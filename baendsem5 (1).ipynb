{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13882310,"sourceType":"datasetVersion","datasetId":8844699}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport timm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"=\"*80)\nprint(\"NOTEBOOK 5: TRANSFORMER MODELS (ViT & Swin Transformer)\")\nprint(\"=\"*80)\n\n# ========== DATASET PATH DETECTION ==========\nprint(\"\\n[0/6] Detecting dataset path...\")\n\n# Check all possible locations\npossible_paths = [\n    '/kaggle/working/split_80_10_10',           # From previous notebook\n    '/kaggle/input/split_dataset/split_80_10_10',\n    '/kaggle/input/split-dataset/split_80_10_10',\n]\n\nSPLIT_DIR = None\nfor path in possible_paths:\n    if os.path.exists(path):\n        train_path = os.path.join(path, 'train')\n        if os.path.exists(train_path):\n            SPLIT_DIR = path\n            print(f\"✓ Dataset found at: {SPLIT_DIR}\")\n            break\n\n# If not found in standard paths, search recursively\nif SPLIT_DIR is None:\n    print(\"Searching recursively for split_80_10_10...\")\n    for search_root in ['/kaggle/working', '/kaggle/input']:\n        if not os.path.exists(search_root):\n            continue\n        for root, dirs, files in os.walk(search_root):\n            if 'split_80_10_10' in root:\n                if os.path.exists(os.path.join(root, 'train')):\n                    SPLIT_DIR = root\n                    print(f\"✓ Found at: {SPLIT_DIR}\")\n                    break\n            if 'train' in dirs and 'val' in dirs and 'test' in dirs:\n                # Check if this looks like our split directory\n                train_classes = os.listdir(os.path.join(root, 'train'))\n                if len(train_classes) >= 4:  # We have 4 classes\n                    SPLIT_DIR = root\n                    print(f\"✓ Found at: {SPLIT_DIR}\")\n                    break\n        if SPLIT_DIR:\n            break\n\nif SPLIT_DIR is None:\n    print(\"\\n❌ Dataset not found in expected locations!\")\n    print(\"\\nPlease check:\")\n    print(\"1. Did you run the notebook that created split_80_10_10?\")\n    print(\"2. Is it saved in /kaggle/working/split_80_10_10?\")\n    print(\"\\nAvailable paths:\")\n    print(\"  /kaggle/working contents:\")\n    try:\n        for item in os.listdir('/kaggle/working'):\n            print(f\"    - {item}\")\n    except:\n        pass\n    raise FileNotFoundError(\"split_80_10_10 directory not found!\")\n\nOUTPUT_DIR = '/kaggle/working'\nTRAIN_DIR = os.path.join(SPLIT_DIR, 'train')\nVAL_DIR = os.path.join(SPLIT_DIR, 'val')\nTEST_DIR = os.path.join(SPLIT_DIR, 'test')\n\nIMG_SIZE = 224\nBATCH_SIZE = 32\nNUM_WORKERS = 4\nNUM_EPOCHS_VIT = 20\nNUM_EPOCHS_SWIN = 20\nLEARNING_RATE = 0.0001\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"\\n✓ Device: {DEVICE}\")\nprint(f\"✓ Using split from: {SPLIT_DIR}\")\n\n# Verify directories\ntry:\n    train_classes = sorted(os.listdir(TRAIN_DIR))\n    val_classes = sorted(os.listdir(VAL_DIR))\n    test_classes = sorted(os.listdir(TEST_DIR))\n    \n    print(f\"\\nVerifying dataset structure:\")\n    print(f\"  Train: {len(train_classes)} classes - {train_classes}\")\n    print(f\"  Val:   {len(val_classes)} classes - {val_classes}\")\n    print(f\"  Test:  {len(test_classes)} classes - {test_classes}\")\n    \n    # Count images\n    train_count = sum(len(os.listdir(os.path.join(TRAIN_DIR, c))) for c in train_classes)\n    val_count = sum(len(os.listdir(os.path.join(VAL_DIR, c))) for c in val_classes)\n    test_count = sum(len(os.listdir(os.path.join(TEST_DIR, c))) for c in test_classes)\n    \n    print(f\"\\n  Total Train images: {train_count}\")\n    print(f\"  Total Val images:   {val_count}\")\n    print(f\"  Total Test images:  {test_count}\")\n    print(f\"  ✓ Dataset verified!\")\nexcept Exception as e:\n    print(f\"\\n❌ Error verifying dataset: {e}\")\n    raise\n\n# ========== 1. AUGMENTATION ==========\nprint(\"\\n[1/6] Defining augmentation...\")\n\ntrain_transform = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.Rotate(limit=20, p=0.5),\n    A.GaussNoise(p=0.2),\n    A.GaussianBlur(blur_limit=3, p=0.2),\n    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n    A.ElasticTransform(p=0.2),\n    A.Normalize(mean=0.5, std=0.5),\n    ToTensorV2(),\n], is_check_shapes=False)\n\nval_test_transform = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE),\n    A.Normalize(mean=0.5, std=0.5),\n    ToTensorV2(),\n], is_check_shapes=False)\n\nprint(\"✓ Augmentation defined\")\n\n# ========== 2. DATASET CLASS ==========\nprint(\"\\n[2/6] Creating dataset class...\")\n\nclass OCTDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        self.class_to_idx = {}\n        \n        classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}\n        \n        for cls in classes:\n            cls_path = os.path.join(root_dir, cls)\n            images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            for img_name in images:\n                self.image_paths.append(os.path.join(cls_path, img_name))\n                self.labels.append(self.class_to_idx[cls])\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        if image is None:\n            image = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image, label\n\nprint(\"✓ Dataset class created\")\n\n# ========== 3. DATALOADERS ==========\nprint(\"\\n[3/6] Creating dataloaders...\")\n\ntrain_dataset = OCTDataset(TRAIN_DIR, transform=train_transform)\nval_dataset = OCTDataset(VAL_DIR, transform=val_test_transform)\ntest_dataset = OCTDataset(TEST_DIR, transform=val_test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\nnum_classes = len(train_dataset.idx_to_class)\nclass_names = list(train_dataset.idx_to_class.values())\n\nprint(f\"✓ Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")\n\n# ========== 4. UTILITY FUNCTIONS ==========\ndef compute_metrics(y_true, y_pred):\n    \"\"\"Compute accuracy, precision, recall, F1\"\"\"\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n    return acc, prec, rec, f1\n\ndef train_transformer_model(model_name, model, train_loader, val_loader, test_loader, num_epochs, learning_rate):\n    \"\"\"Generic training function for transformer models\"\"\"\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"TRAINING {model_name.upper()}\")\n    print(f\"{'='*80}\")\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n    \n    best_val_acc = 0.0\n    best_model_path = os.path.join(OUTPUT_DIR, f'{model_name}_best_80_10_10.pth')\n    \n    train_losses, val_losses = [], []\n    train_accs, val_accs = [], []\n    train_precisions, val_precisions = [], []\n    train_recalls, val_recalls = [], []\n    train_f1s, val_f1s = [], []\n    \n    # ===== TRAINING LOOP =====\n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        train_loss = 0.0\n        train_preds, train_labels = [], []\n        \n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [TRAIN]\", leave=False)\n        for images, labels in pbar:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            train_preds.extend(preds.cpu().numpy())\n            train_labels.extend(labels.cpu().numpy())\n        \n        train_loss /= len(train_loader)\n        train_acc, train_prec, train_rec, train_f1 = compute_metrics(train_labels, train_preds)\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n        train_precisions.append(train_prec)\n        train_recalls.append(train_rec)\n        train_f1s.append(train_f1)\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        val_preds, val_labels = [], []\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, preds = torch.max(outputs, 1)\n                val_preds.extend(preds.cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n        \n        val_loss /= len(val_loader)\n        val_acc, val_prec, val_rec, val_f1 = compute_metrics(val_labels, val_preds)\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n        val_precisions.append(val_prec)\n        val_recalls.append(val_rec)\n        val_f1s.append(val_f1)\n        \n        scheduler.step()\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), best_model_path)\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}: TL={train_loss:.4f} TA={train_acc:.4f} TF1={train_f1:.4f} | VL={val_loss:.4f} VA={val_acc:.4f} VF1={val_f1:.4f}\")\n    \n    print(\"✓ Training complete!\")\n    \n    # ===== TESTING =====\n    print(f\"\\nTesting {model_name}...\")\n    model.load_state_dict(torch.load(best_model_path))\n    model.eval()\n    \n    results = {}\n    for split_name, loader in [(\"Train\", train_loader), (\"Validation\", val_loader), (\"Test\", test_loader)]:\n        preds, labels = [], []\n        with torch.no_grad():\n            pbar = tqdm(loader, desc=f\"Computing {split_name} metrics\", leave=False)\n            for images, image_labels in pbar:\n                images, image_labels = images.to(DEVICE), image_labels.to(DEVICE)\n                outputs = model(images)\n                _, batch_preds = torch.max(outputs, 1)\n                preds.extend(batch_preds.cpu().numpy())\n                labels.extend(image_labels.cpu().numpy())\n        \n        acc, prec, rec, f1 = compute_metrics(labels, preds)\n        results[split_name] = {\n            'Accuracy': acc,\n            'Precision': prec,\n            'Recall': rec,\n            'F1-Score': f1,\n            'Predictions': preds,\n            'Labels': labels\n        }\n    \n    # ===== DISPLAY RESULTS =====\n    print(\"\\n\" + \"=\"*80)\n    print(f\"{model_name.upper()} - COMPREHENSIVE METRICS (80/10/10 SPLIT)\")\n    print(\"=\"*80)\n    \n    for split_name in [\"Train\", \"Validation\", \"Test\"]:\n        print(f\"\\n{'─'*80}\")\n        print(f\"  {split_name.upper()} SET METRICS\")\n        print(f\"{'─'*80}\")\n        print(f\"  Accuracy   : {results[split_name]['Accuracy']:.4f}\")\n        print(f\"  Precision  : {results[split_name]['Precision']:.4f}\")\n        print(f\"  Recall     : {results[split_name]['Recall']:.4f}\")\n        print(f\"  F1-Score   : {results[split_name]['F1-Score']:.4f}\")\n    \n    print(f\"\\n{'─'*80}\")\n    print(\"TEST SET - DETAILED CLASSIFICATION REPORT\")\n    print(f\"{'─'*80}\")\n    print(classification_report(results[\"Test\"]['Labels'], results[\"Test\"]['Predictions'], target_names=class_names))\n    \n    # ===== VISUALIZATIONS =====\n    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n    \n    axes[0, 0].plot(train_losses, label='Train', marker='o', linewidth=2)\n    axes[0, 0].plot(val_losses, label='Val', marker='s', linewidth=2)\n    axes[0, 0].set_xlabel('Epoch')\n    axes[0, 0].set_ylabel('Loss')\n    axes[0, 0].set_title(f'{model_name}: Training & Validation Loss')\n    axes[0, 0].legend()\n    axes[0, 0].grid(True, alpha=0.3)\n    \n    axes[0, 1].plot(train_accs, label='Train', marker='o', linewidth=2)\n    axes[0, 1].plot(val_accs, label='Val', marker='s', linewidth=2)\n    axes[0, 1].set_xlabel('Epoch')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_title(f'{model_name}: Training & Validation Accuracy')\n    axes[0, 1].legend()\n    axes[0, 1].grid(True, alpha=0.3)\n    \n    axes[1, 0].plot(train_precisions, label='Train', marker='o', linewidth=2)\n    axes[1, 0].plot(val_precisions, label='Val', marker='s', linewidth=2)\n    axes[1, 0].set_xlabel('Epoch')\n    axes[1, 0].set_ylabel('Precision')\n    axes[1, 0].set_title(f'{model_name}: Training & Validation Precision')\n    axes[1, 0].legend()\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    axes[1, 1].plot(train_f1s, label='Train', marker='o', linewidth=2)\n    axes[1, 1].plot(val_f1s, label='Val', marker='s', linewidth=2)\n    axes[1, 1].set_xlabel('Epoch')\n    axes[1, 1].set_ylabel('F1-Score')\n    axes[1, 1].set_title(f'{model_name}: Training & Validation F1-Score')\n    axes[1, 1].legend()\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, f'{model_name}_80_10_10_all_metrics_curves.png'), dpi=300, bbox_inches='tight')\n    print(f\"✓ Saved: {model_name}_80_10_10_all_metrics_curves.png\")\n    plt.close()\n    \n    # Confusion matrices\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    for idx, (split_name, ax) in enumerate(zip([\"Train\", \"Validation\", \"Test\"], axes)):\n        cm = confusion_matrix(results[split_name]['Labels'], results[split_name]['Predictions'])\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n        ax.set_xlabel('Predicted')\n        ax.set_ylabel('Actual')\n        ax.set_title(f'{model_name}: {split_name} Confusion Matrix')\n    \n    plt.tight_layout()\n    plt.savefig(os.path.join(OUTPUT_DIR, f'{model_name}_80_10_10_all_confusion_matrices.png'), dpi=300, bbox_inches='tight')\n    print(f\"✓ Saved: {model_name}_80_10_10_all_confusion_matrices.png\")\n    plt.close()\n    \n    # Save metrics to CSV\n    metrics_df = pd.DataFrame({\n        'Set': ['Train', 'Validation', 'Test'],\n        'Accuracy': [results['Train']['Accuracy'], results['Validation']['Accuracy'], results['Test']['Accuracy']],\n        'Precision': [results['Train']['Precision'], results['Validation']['Precision'], results['Test']['Precision']],\n        'Recall': [results['Train']['Recall'], results['Validation']['Recall'], results['Test']['Recall']],\n        'F1-Score': [results['Train']['F1-Score'], results['Validation']['F1-Score'], results['Test']['F1-Score']]\n    })\n    \n    metrics_df.to_csv(os.path.join(OUTPUT_DIR, f'{model_name}_80_10_10_comprehensive_metrics.csv'), index=False)\n    print(f\"✓ Saved: {model_name}_80_10_10_comprehensive_metrics.csv\")\n    \n    return results, metrics_df\n\n# ========== 5A. VISION TRANSFORMER (ViT) ==========\nprint(\"\\n[4/6] Training Vision Transformer (ViT)...\")\n\nvit_model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\nvit_model = vit_model.to(DEVICE)\nprint(\"✓ ViT loaded\")\n\nvit_results, vit_metrics = train_transformer_model(\n    'vit', vit_model, train_loader, val_loader, test_loader, \n    NUM_EPOCHS_VIT, LEARNING_RATE\n)\n\n# ========== 5B. SWIN TRANSFORMER ==========\nprint(\"\\n[5/6] Training Swin Transformer...\")\n\nswin_model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=num_classes)\nswin_model = swin_model.to(DEVICE)\nprint(\"✓ Swin Transformer loaded\")\n\nswin_results, swin_metrics = train_transformer_model(\n    'swin', swin_model, train_loader, val_loader, test_loader, \n    NUM_EPOCHS_SWIN, LEARNING_RATE\n)\n\n# ========== 6. COMPARISON TABLE ==========\nprint(\"\\n[6/6] Creating comparison tables...\")\n\n# Individual model tables\nfor df, name in zip([vit_metrics, swin_metrics], ['vit', 'swin']):\n    plt.figure(figsize=(8, 2))\n    table = plt.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center')\n    table.auto_set_font_size(False)\n    table.set_fontsize(12)\n    table.scale(1.3, 1.7)\n    plt.axis('off')\n    plt.title(f\"{name.upper()} - All Metrics\", fontsize=14)\n    plt.savefig(os.path.join(OUTPUT_DIR, f'{name}_all_metrics_table.png'), dpi=300, bbox_inches='tight')\n    plt.close()\n\n# Combined comparison (Test Set Only)\ncombined = pd.concat([\n    vit_metrics[vit_metrics[\"Set\"].str.lower() == \"test\"].assign(Model='ViT'),\n    swin_metrics[swin_metrics[\"Set\"].str.lower() == \"test\"].assign(Model='Swin')\n], ignore_index=True)[[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]]\n\nplt.figure(figsize=(8, 2))\ntable = plt.table(cellText=combined.values, colLabels=combined.columns, loc='center', cellLoc='center')\ntable.auto_set_font_size(False)\ntable.set_fontsize(12)\ntable.scale(1.3, 1.7)\nplt.axis('off')\nplt.title(\"Transformer Models - Test Set Comparison\", fontsize=14)\nplt.savefig(os.path.join(OUTPUT_DIR, 'transformers_comparison_table.png'), dpi=300, bbox_inches='tight')\nplt.close()\n\nprint(\"✓ All comparison tables saved!\")\n\n# ========== FINAL SUMMARY ==========\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY: ALL TRANSFORMER MODELS TRAINED\")\nprint(\"=\"*80)\nprint(\"\\nViT Test Results:\")\nprint(f\"  Accuracy:  {vit_results['Test']['Accuracy']:.4f}\")\nprint(f\"  Precision: {vit_results['Test']['Precision']:.4f}\")\nprint(f\"  Recall:    {vit_results['Test']['Recall']:.4f}\")\nprint(f\"  F1-Score:  {vit_results['Test']['F1-Score']:.4f}\")\n\nprint(\"\\nSwin Transformer Test Results:\")\nprint(f\"  Accuracy:  {swin_results['Test']['Accuracy']:.4f}\")\nprint(f\"  Precision: {swin_results['Test']['Precision']:.4f}\")\nprint(f\"  Recall:    {swin_results['Test']['Recall']:.4f}\")\nprint(f\"  F1-Score:  {swin_results['Test']['F1-Score']:.4f}\")\n\nprint(f\"\\n✓ All outputs saved to: {OUTPUT_DIR}\")\nprint(\"=\"*80)\n\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:49:50.416586Z","iopub.execute_input":"2025-11-26T15:49:50.417337Z","iopub.status.idle":"2025-11-26T20:29:55.698861Z","shell.execute_reply.started":"2025-11-26T15:49:50.417313Z","shell.execute_reply":"2025-11-26T20:29:55.697943Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nNOTEBOOK 5: TRANSFORMER MODELS (ViT & Swin Transformer)\n================================================================================\n\n[0/6] Detecting dataset path...\nSearching recursively for split_80_10_10...\n✓ Found at: /kaggle/input/split-dataset\n\n✓ Device: cuda\n✓ Using split from: /kaggle/input/split-dataset\n\nVerifying dataset structure:\n  Train: 4 classes - ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n  Val:   4 classes - ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n  Test:  4 classes - ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n\n  Total Train images: 15967\n  Total Val images:   2000\n  Total Test images:  2002\n  ✓ Dataset verified!\n\n[1/6] Defining augmentation...\n✓ Augmentation defined\n\n[2/6] Creating dataset class...\n✓ Dataset class created\n\n[3/6] Creating dataloaders...\n✓ Train: 15967 | Val: 2000 | Test: 2002\n\n[4/6] Training Vision Transformer (ViT)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d14c031d015498da202ff0a238357b4"}},"metadata":{}},{"name":"stdout","text":"✓ ViT loaded\n\n================================================================================\nTRAINING VIT\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20: TL=0.8139 TA=0.6741 TF1=0.6487 | VL=0.6642 VA=0.7290 VF1=0.7169\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20: TL=0.7013 TA=0.7128 TF1=0.6953 | VL=0.6388 VA=0.7385 VF1=0.7276\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20: TL=0.6774 TA=0.7234 TF1=0.7061 | VL=0.6053 VA=0.7315 VF1=0.7167\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20: TL=0.6623 TA=0.7265 TF1=0.7111 | VL=0.5933 VA=0.7510 VF1=0.7361\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20: TL=0.6382 TA=0.7350 TF1=0.7204 | VL=0.5717 VA=0.7625 VF1=0.7500\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20: TL=0.6162 TA=0.7467 TF1=0.7340 | VL=0.5485 VA=0.7630 VF1=0.7481\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20: TL=0.6079 TA=0.7465 TF1=0.7338 | VL=0.5727 VA=0.7615 VF1=0.7477\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20: TL=0.5995 TA=0.7512 TF1=0.7388 | VL=0.5526 VA=0.7685 VF1=0.7552\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20: TL=0.5878 TA=0.7543 TF1=0.7428 | VL=0.5366 VA=0.7740 VF1=0.7651\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20: TL=0.5734 TA=0.7601 TF1=0.7491 | VL=0.5432 VA=0.7720 VF1=0.7592\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20: TL=0.5603 TA=0.7643 TF1=0.7539 | VL=0.5354 VA=0.7705 VF1=0.7615\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20: TL=0.5415 TA=0.7718 TF1=0.7624 | VL=0.5336 VA=0.7815 VF1=0.7723\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20: TL=0.5308 TA=0.7752 TF1=0.7662 | VL=0.5478 VA=0.7745 VF1=0.7654\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20: TL=0.5240 TA=0.7817 TF1=0.7730 | VL=0.5350 VA=0.7705 VF1=0.7657\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20: TL=0.5132 TA=0.7832 TF1=0.7752 | VL=0.5164 VA=0.7860 VF1=0.7788\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20: TL=0.4988 TA=0.7888 TF1=0.7815 | VL=0.5100 VA=0.7885 VF1=0.7803\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20: TL=0.4930 TA=0.7913 TF1=0.7843 | VL=0.5206 VA=0.7830 VF1=0.7752\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20: TL=0.4819 TA=0.7947 TF1=0.7881 | VL=0.5191 VA=0.7835 VF1=0.7757\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20: TL=0.4810 TA=0.7957 TF1=0.7891 | VL=0.5227 VA=0.7845 VF1=0.7765\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20: TL=0.4774 TA=0.7964 TF1=0.7899 | VL=0.5199 VA=0.7840 VF1=0.7761\n✓ Training complete!\n\nTesting vit...\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nVIT - COMPREHENSIVE METRICS (80/10/10 SPLIT)\n================================================================================\n\n────────────────────────────────────────────────────────────────────────────────\n  TRAIN SET METRICS\n────────────────────────────────────────────────────────────────────────────────\n  Accuracy   : 0.7928\n  Precision  : 0.8174\n  Recall     : 0.7928\n  F1-Score   : 0.7857\n\n────────────────────────────────────────────────────────────────────────────────\n  VALIDATION SET METRICS\n────────────────────────────────────────────────────────────────────────────────\n  Accuracy   : 0.7885\n  Precision  : 0.8122\n  Recall     : 0.7885\n  F1-Score   : 0.7803\n\n────────────────────────────────────────────────────────────────────────────────\n  TEST SET METRICS\n────────────────────────────────────────────────────────────────────────────────\n  Accuracy   : 0.7727\n  Precision  : 0.7990\n  Recall     : 0.7727\n  F1-Score   : 0.7628\n\n────────────────────────────────────────────────────────────────────────────────\nTEST SET - DETAILED CLASSIFICATION REPORT\n────────────────────────────────────────────────────────────────────────────────\n              precision    recall  f1-score   support\n\n         CNV       0.71      0.95      0.81       891\n         DME       0.93      0.50      0.65       274\n      DRUSEN       0.85      0.48      0.61       206\n      NORMAL       0.86      0.73      0.79       631\n\n    accuracy                           0.77      2002\n   macro avg       0.83      0.67      0.72      2002\nweighted avg       0.80      0.77      0.76      2002\n\n✓ Saved: vit_80_10_10_all_metrics_curves.png\n✓ Saved: vit_80_10_10_all_confusion_matrices.png\n✓ Saved: vit_80_10_10_comprehensive_metrics.csv\n\n[5/6] Training Swin Transformer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff0208fa803245e3b9a93786ef91213c"}},"metadata":{}},{"name":"stdout","text":"✓ Swin Transformer loaded\n\n================================================================================\nTRAINING SWIN\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20: TL=0.7639 TA=0.6885 TF1=0.6617 | VL=0.5981 VA=0.7580 VF1=0.7487\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20: TL=0.6480 TA=0.7318 TF1=0.7160 | VL=0.5821 VA=0.7470 VF1=0.7397\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20: TL=0.6303 TA=0.7411 TF1=0.7275 | VL=0.5259 VA=0.7790 VF1=0.7676\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20: TL=0.6047 TA=0.7507 TF1=0.7381 | VL=0.5113 VA=0.7840 VF1=0.7773\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20: TL=0.5879 TA=0.7562 TF1=0.7446 | VL=0.5128 VA=0.7845 VF1=0.7758\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20: TL=0.5780 TA=0.7593 TF1=0.7478 | VL=0.5135 VA=0.7855 VF1=0.7768\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20: TL=0.5582 TA=0.7640 TF1=0.7546 | VL=0.5574 VA=0.7745 VF1=0.7612\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20: TL=0.5548 TA=0.7687 TF1=0.7593 | VL=0.5268 VA=0.7830 VF1=0.7732\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20: TL=0.5434 TA=0.7725 TF1=0.7631 | VL=0.5044 VA=0.7850 VF1=0.7771\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20: TL=0.5374 TA=0.7752 TF1=0.7667 | VL=0.4961 VA=0.7890 VF1=0.7813\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20: TL=0.5268 TA=0.7799 TF1=0.7713 | VL=0.5025 VA=0.7920 VF1=0.7842\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20: TL=0.5166 TA=0.7807 TF1=0.7728 | VL=0.4952 VA=0.7900 VF1=0.7816\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20: TL=0.5051 TA=0.7811 TF1=0.7736 | VL=0.5014 VA=0.7895 VF1=0.7822\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20: TL=0.4990 TA=0.7876 TF1=0.7805 | VL=0.4997 VA=0.7865 VF1=0.7798\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20: TL=0.4889 TA=0.7908 TF1=0.7842 | VL=0.4963 VA=0.7960 VF1=0.7891\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20: TL=0.4847 TA=0.7937 TF1=0.7876 | VL=0.4972 VA=0.7920 VF1=0.7852\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20: TL=0.4816 TA=0.7938 TF1=0.7873 | VL=0.5005 VA=0.7965 VF1=0.7898\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20: TL=0.4731 TA=0.7955 TF1=0.7895 | VL=0.4975 VA=0.7920 VF1=0.7854\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20: TL=0.4727 TA=0.7982 TF1=0.7922 | VL=0.4962 VA=0.7960 VF1=0.7892\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20: TL=0.4703 TA=0.7975 TF1=0.7913 | VL=0.4962 VA=0.7970 VF1=0.7902\n✓ Training complete!\n\nTesting swin...\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nSWIN - COMPREHENSIVE METRICS (80/10/10 SPLIT)\n================================================================================\n\n────────────────────────────────────────────────────────────────────────────────\n  TRAIN SET METRICS\n────────────────────────────────────────────────────────────────────────────────\n  Accuracy   : 0.8022\n  Precision  : 0.8340\n  Recall     : 0.8022\n  F1-Score   : 0.7965\n\n────────────────────────────────────────────────────────────────────────────────\n  VALIDATION SET METRICS\n────────────────────────────────────────────────────────────────────────────────\n  Accuracy   : 0.7970\n  Precision  : 0.8315\n  Recall     : 0.7970\n  F1-Score   : 0.7902\n\n────────────────────────────────────────────────────────────────────────────────\n  TEST SET METRICS\n────────────────────────────────────────────────────────────────────────────────\n  Accuracy   : 0.7782\n  Precision  : 0.8102\n  Recall     : 0.7782\n  F1-Score   : 0.7698\n\n────────────────────────────────────────────────────────────────────────────────\nTEST SET - DETAILED CLASSIFICATION REPORT\n────────────────────────────────────────────────────────────────────────────────\n              precision    recall  f1-score   support\n\n         CNV       0.70      0.97      0.81       891\n         DME       0.88      0.54      0.67       274\n      DRUSEN       0.89      0.50      0.64       206\n      NORMAL       0.91      0.71      0.80       631\n\n    accuracy                           0.78      2002\n   macro avg       0.84      0.68      0.73      2002\nweighted avg       0.81      0.78      0.77      2002\n\n✓ Saved: swin_80_10_10_all_metrics_curves.png\n✓ Saved: swin_80_10_10_all_confusion_matrices.png\n✓ Saved: swin_80_10_10_comprehensive_metrics.csv\n\n[6/6] Creating comparison tables...\n✓ All comparison tables saved!\n\n================================================================================\nSUMMARY: ALL TRANSFORMER MODELS TRAINED\n================================================================================\n\nViT Test Results:\n  Accuracy:  0.7727\n  Precision: 0.7990\n  Recall:    0.7727\n  F1-Score:  0.7628\n\nSwin Transformer Test Results:\n  Accuracy:  0.7782\n  Precision: 0.8102\n  Recall:    0.7782\n  F1-Score:  0.7698\n\n✓ All outputs saved to: /kaggle/working\n================================================================================\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}