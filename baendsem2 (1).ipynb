{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13869886,"sourceType":"datasetVersion","datasetId":8837084}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport random\nimport shutil\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"=\"*80)\nprint(\"OCT IMAGE CLASSIFICATION PROJECT - NOTEBOOK 2: SEGMENTATION\")\nprint(\"Classical Segmentation (Otsu + Morphology)\")\nprint(\"=\"*80)\n\n# ========== CONFIGURATION ==========\nDATA_DIR = '/kaggle/input/oct2017/OCT2017'\nOUTPUT_DIR = '/kaggle/working'\nSEGMENTED_DIR = os.path.join(OUTPUT_DIR, 'segmented_images')\nCOLORMAP_DIR = os.path.join(OUTPUT_DIR, 'segmented_colormaps')\nOVERLAY_DIR = os.path.join(OUTPUT_DIR, 'segmented_overlays')\nVISUALIZATION_DIR = os.path.join(OUTPUT_DIR, 'segmentation_vis')\n\nos.makedirs(SEGMENTED_DIR, exist_ok=True)\nos.makedirs(COLORMAP_DIR, exist_ok=True)\nos.makedirs(OVERLAY_DIR, exist_ok=True)\nos.makedirs(VISUALIZATION_DIR, exist_ok=True)\n\nTARGET_SIZE = (224, 224)\nNUM_TOTAL = 20000  # Change to 200 for quick test\nDEVICE = 'cpu'\n\nprint(f\"âœ“ Device: {DEVICE}\")\nprint(f\"âœ“ Target image size: {TARGET_SIZE}\")\nprint(f\"âœ“ Processing {NUM_TOTAL} images total\")\n\n# ========== SEGMENTATION FUNCTION ==========\ndef segment_oct_image(image_np):\n    \"\"\"\n    Classical segmentation using Otsu thresholding + morphology\n    Returns: segmented image, binary mask\n    \"\"\"\n    # Convert to grayscale\n    if len(image_np.shape) == 3:\n        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image_np\n    \n    # Apply Gaussian blur to reduce noise\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n    \n    # Otsu's thresholding - automatically finds best threshold\n    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    \n    # Morphological operations to clean up\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n    morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n    morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=1)\n    \n    # Find contours\n    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    # Create mask from largest contour (the actual retina ROI)\n    mask = np.zeros_like(gray)\n    if contours:\n        largest_contour = max(contours, key=cv2.contourArea)\n        cv2.drawContours(mask, [largest_contour], -1, 255, -1)\n    else:\n        mask = np.ones_like(gray) * 255\n    \n    # Apply mask to original image\n    if len(image_np.shape) == 3:\n        segmented = cv2.bitwise_and(image_np, image_np, mask=mask)\n    else:\n        segmented = cv2.bitwise_and(gray, gray, mask=mask)\n    \n    return segmented, mask\n\n# ========== COLORMAP FUNCTION ==========\ndef save_colormap(mask_array, out_path):\n    \"\"\"Convert binary mask to colored visualization\"\"\"\n    mask_norm = (mask_array / 255.0) if mask_array.max() > 1 else mask_array\n    cmap = plt.get_cmap('viridis')\n    rgba = cmap(mask_norm)\n    rgb = np.uint8(rgba[:,:,:3] * 255)\n    Image.fromarray(rgb).save(out_path)\n\n# ========== OVERLAY FUNCTION ==========\ndef make_overlay(orig_img_array, mask_array, out_path):\n    \"\"\"Create overlay: original + segmentation boundary\"\"\"\n    overlay = cv2.cvtColor(orig_img_array, cv2.COLOR_GRAY2RGB)\n    contours, _ = cv2.findContours(mask_array, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    overlay = cv2.drawContours(overlay, contours, -1, (0, 255, 0), 2)\n    Image.fromarray(overlay).save(out_path)\n\n# ========== BUILD IMAGE INDEX ==========\nprint(\"\\n[1/6] Building image index...\")\nimage_index = []\nsplits = ['train', 'val', 'test']\n\nfor split in splits:\n    split_path = os.path.join(DATA_DIR, split)\n    if not os.path.exists(split_path):\n        continue\n    for cls in os.listdir(split_path):\n        class_path = os.path.join(split_path, cls)\n        if not os.path.isdir(class_path):\n            continue\n        img_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n        for fname in img_files:\n            image_index.append((split, cls, fname))\n\nprint(f\"âœ“ Total images found: {len(image_index)}\")\n\n# ========== SAMPLE IMAGES ==========\nprint(f\"\\n[2/6] Sampling {NUM_TOTAL} random images...\")\nrandom.seed(42)\nif len(image_index) > NUM_TOTAL:\n    image_index = random.sample(image_index, NUM_TOTAL)\nprint(f\"âœ“ Processing {len(image_index)} images\")\n\n# ========== RUN SEGMENTATION ==========\nprint(f\"\\n[3/6] Running classical segmentation on all images...\")\nsegmentation_stats = []\nprocessed = 0\n\nfor (split, cls, fname) in tqdm(image_index, desc=\"Segmenting\"):\n    img_path = os.path.join(DATA_DIR, split, cls, fname)\n    \n    # Load image\n    image = Image.open(img_path).convert('RGB')\n    image_np = np.array(image)\n    \n    # Resize\n    image_resized = cv2.resize(image_np, TARGET_SIZE)\n    \n    # Segment\n    segmented, mask = segment_oct_image(image_resized)\n    \n    # Create output directories\n    seg_cls_dir = os.path.join(SEGMENTED_DIR, split, cls)\n    color_cls_dir = os.path.join(COLORMAP_DIR, split, cls)\n    overlay_cls_dir = os.path.join(OVERLAY_DIR, split, cls)\n    \n    os.makedirs(seg_cls_dir, exist_ok=True)\n    os.makedirs(color_cls_dir, exist_ok=True)\n    os.makedirs(overlay_cls_dir, exist_ok=True)\n    \n    # Save segmented image\n    img_name = os.path.basename(img_path)\n    seg_output_path = os.path.join(seg_cls_dir, img_name)\n    Image.fromarray(segmented).save(seg_output_path)\n    \n    # Save colormap\n    colormap_path = os.path.join(color_cls_dir, img_name.replace('.', '_colormap.'))\n    save_colormap(mask, colormap_path)\n    \n    # Save overlay\n    overlay_path = os.path.join(overlay_cls_dir, img_name.replace('.', '_overlay.'))\n    make_overlay(cv2.cvtColor(image_resized, cv2.COLOR_RGB2GRAY), mask, overlay_path)\n    \n    # Track stats\n    total_pixels = mask.size\n    foreground_pixels = np.sum(mask > 0)\n    foreground_ratio = foreground_pixels / total_pixels\n    \n    segmentation_stats.append({\n        'split': split,\n        'class': cls,\n        'original_path': img_path,\n        'segmented_path': seg_output_path,\n        'foreground_ratio': foreground_ratio\n    })\n    \n    processed += 1\n\nprint(f\"âœ“ Segmentation complete! Processed {processed} images\")\n\n# ========== SAVE STATISTICS ==========\nprint(f\"\\n[4/6] Computing and saving segmentation statistics...\")\ndf_stats = pd.DataFrame(segmentation_stats)\ndf_stats.to_csv(os.path.join(OUTPUT_DIR, 'segmentation_mapping.csv'), index=False)\nprint(f\"âœ“ Saved segmentation mapping\")\n\n# Print summary\nprint(\"\\n\" + \"=\"*60)\nprint(\"SEGMENTATION QUALITY METRICS\")\nprint(\"=\"*60)\nprint(df_stats.groupby('class')['foreground_ratio'].describe())\n\n# ========== VISUALIZATIONS ==========\nprint(f\"\\n[5/6] Creating visualizations...\")\n\n# Sample visualization\nfig, axes = plt.subplots(5, 3, figsize=(15, 20))\nfig.suptitle('Segmentation Results: Original vs Mask vs Overlay', fontsize=16, fontweight='bold')\n\nsample_indices = np.random.choice(len(image_index), min(5, len(image_index)), replace=False)\n\nfor idx, sample_idx in enumerate(sample_indices):\n    split, cls, fname = image_index[sample_idx]\n    img_path = os.path.join(DATA_DIR, split, cls, fname)\n    image = Image.open(img_path).convert('RGB')\n    image_np = np.array(image)\n    image_resized = cv2.resize(image_np, TARGET_SIZE)\n    segmented, mask = segment_oct_image(image_resized)\n    \n    # Original\n    axes[idx, 0].imshow(image_resized, cmap='gray')\n    axes[idx, 0].set_title(f'Original - {cls}', fontsize=10, fontweight='bold')\n    axes[idx, 0].axis('off')\n    \n    # Mask\n    axes[idx, 1].imshow(mask, cmap='gray')\n    axes[idx, 1].set_title('Segmentation Mask', fontsize=10)\n    axes[idx, 1].axis('off')\n    \n    # Segmented\n    axes[idx, 2].imshow(segmented, cmap='gray')\n    axes[idx, 2].set_title('Segmented ROI', fontsize=10)\n    axes[idx, 2].axis('off')\n\nplt.tight_layout()\nplt.savefig(os.path.join(VISUALIZATION_DIR, 'segmentation_comparison.png'), dpi=300, bbox_inches='tight')\nprint(f\"âœ“ Saved segmentation comparison visualization\")\nplt.close()\n\n# ========== VERIFY DATASET ==========\nprint(f\"\\n[6/6] Verifying segmented dataset...\")\n\nverification = {}\nfor split in ['train', 'val', 'test']:\n    split_path = os.path.join(SEGMENTED_DIR, split)\n    if not os.path.exists(split_path):\n        continue\n    verification[split] = {}\n    classes = [d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, d))]\n    for cls in classes:\n        cls_path = os.path.join(split_path, cls)\n        images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n        verification[split][cls] = len(images)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SEGMENTED DATASET VERIFICATION\")\nprint(\"=\"*60)\nfor split, classes in verification.items():\n    print(f\"\\n{split.upper()}:\")\n    for cls, count in classes.items():\n        print(f\"  {cls}: {count} images\")\n\n# ========== CREATE SUMMARY REPORT ==========\nprint(\"\\n\" + \"=\"*60)\nprint(\"Creating summary report...\")\nprint(\"=\"*60)\n\nsummary_report = f\"\"\"\n{'='*80}\nSEGMENTATION PREPROCESSING - SUMMARY REPORT\n{'='*80}\n\n1. DATASET INFORMATION\n   - Total images processed: {len(df_stats)}\n   - Train split: {len(df_stats[df_stats['split']=='train'])} images\n   - Validation split: {len(df_stats[df_stats['split']=='val'])} images\n   - Test split: {len(df_stats[df_stats['split']=='test'])} images\n\n2. SEGMENTATION METHOD\n   - Algorithm: Otsu Thresholding + Morphological Operations\n   - Target size: {TARGET_SIZE}\n   - Processing: Gaussian Blur â†’ Otsu â†’ Morphology â†’ Largest Contour â†’ ROI Extraction\n\n3. OUTPUT LOCATION\n   - Segmented images: {SEGMENTED_DIR}\n   - Colorized masks: {COLORMAP_DIR}\n   - Overlay visualizations: {OVERLAY_DIR}\n   - Mapping file: segmentation_mapping.csv\n\n4. QUALITY METRICS (Average across all classes)\n   - Mean foreground ratio: {df_stats['foreground_ratio'].mean():.3f}\n   - Std foreground ratio: {df_stats['foreground_ratio'].std():.3f}\n   - Min foreground ratio: {df_stats['foreground_ratio'].min():.3f}\n   - Max foreground ratio: {df_stats['foreground_ratio'].max():.3f}\n\n5. METHOD ADVANTAGES\n   âœ“ Fast processing (no training required)\n   âœ“ Reproducible and interpretable\n   âœ“ Well-suited for OCT images with clear tissue/background contrast\n   âœ“ Robust to image variations\n\n6. NEXT STEPS\n   - Proceed to Notebook 3 for data augmentation and preprocessing\n   - Use segmented images as input for your classification models\n   - All outputs ready for downstream ML pipelines\n\n{'='*80}\n\"\"\"\n\nprint(summary_report)\n\nwith open(os.path.join(OUTPUT_DIR, 'segmentation_report.txt'), 'w') as f:\n    f.write(summary_report)\n\n# ========== ZIP OUTPUTS ==========\nprint(\"\\nZipping outputs for download...\")\nshutil.make_archive(os.path.join(OUTPUT_DIR, 'segmented_images'), 'zip', SEGMENTED_DIR)\nprint(\"âœ“ Segmented images zipped: segmented_images.zip\")\n\nshutil.make_archive(os.path.join(OUTPUT_DIR, 'segmented_colormaps'), 'zip', COLORMAP_DIR)\nprint(\"âœ“ Colorized masks zipped: segmented_colormaps.zip\")\n\nshutil.make_archive(os.path.join(OUTPUT_DIR, 'segmented_overlays'), 'zip', OVERLAY_DIR)\nprint(\"âœ“ Overlays zipped: segmented_overlays.zip\")\n\n# ========== FINAL SUMMARY ==========\nprint(\"\\n\" + \"=\"*80)\nprint(\"NOTEBOOK 2 COMPLETED SUCCESSFULLY!\")\nprint(\"=\"*80)\nprint(f\"\\nâœ“ Segmented images saved to: {SEGMENTED_DIR}\")\nprint(f\"âœ“ Total images processed: {len(df_stats)}\")\nprint(f\"\\nGenerated output files:\")\nprint(f\"  1. segmented_images.zip         (ROI-masked images)\")\nprint(f\"  2. segmented_colormaps.zip      (Colored mask visualizations)\")\nprint(f\"  3. segmented_overlays.zip       (Original + mask overlays)\")\nprint(f\"  4. segmentation_mapping.csv     (Image-to-output mapping)\")\nprint(f\"  5. segmentation_report.txt      (Summary report)\")\nprint(f\"  6. segmentation_comparison.png  (Visual comparison)\")\nprint(f\"\\nðŸ“Œ NEXT STEP: Run Notebook 3 for Preprocessing & Augmentation\")\nprint(\"=\"*80)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-26T11:01:36.302981Z","iopub.execute_input":"2025-11-26T11:01:36.303295Z","iopub.status.idle":"2025-11-26T11:06:29.008791Z","shell.execute_reply.started":"2025-11-26T11:01:36.303273Z","shell.execute_reply":"2025-11-26T11:06:29.008078Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nOCT IMAGE CLASSIFICATION PROJECT - NOTEBOOK 2: SEGMENTATION\nClassical Segmentation (Otsu + Morphology)\n================================================================================\nâœ“ Device: cpu\nâœ“ Target image size: (224, 224)\nâœ“ Processing 20000 images total\n\n[1/6] Building image index...\nâœ“ Total images found: 84484\n\n[2/6] Sampling 20000 random images...\nâœ“ Processing 20000 images\n\n[3/6] Running classical segmentation on all images...\n","output_type":"stream"},{"name":"stderr","text":"Segmenting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [04:33<00:00, 73.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ“ Segmentation complete! Processed 20000 images\n\n[4/6] Computing and saving segmentation statistics...\nâœ“ Saved segmentation mapping\n\n============================================================\nSEGMENTATION QUALITY METRICS\n============================================================\n         count      mean       std       min       25%       50%       75%  \\\nclass                                                                        \nCNV     8902.0  0.181105  0.082741  0.008849  0.107825  0.200943  0.241684   \nDME     2738.0  0.164061  0.082225  0.013194  0.088394  0.177087  0.226144   \nDRUSEN  2057.0  0.155218  0.078921  0.012297  0.078444  0.170839  0.214505   \nNORMAL  6303.0  0.145180  0.072294  0.013393  0.075096  0.160176  0.200155   \n\n             max  \nclass             \nCNV     0.718212  \nDME     0.573202  \nDRUSEN  0.664740  \nNORMAL  0.562938  \n\n[5/6] Creating visualizations...\nâœ“ Saved segmentation comparison visualization\n\n[6/6] Verifying segmented dataset...\n\n============================================================\nSEGMENTED DATASET VERIFICATION\n============================================================\n\nTRAIN:\n  DME: 2686 images\n  CNV: 8847 images\n  NORMAL: 6242 images\n  DRUSEN: 1995 images\n\nVAL:\n  CNV: 1 images\n  NORMAL: 2 images\n  DRUSEN: 1 images\n\nTEST:\n  DME: 52 images\n  CNV: 54 images\n  NORMAL: 59 images\n  DRUSEN: 61 images\n\n============================================================\nCreating summary report...\n============================================================\n\n================================================================================\nSEGMENTATION PREPROCESSING - SUMMARY REPORT\n================================================================================\n\n1. DATASET INFORMATION\n   - Total images processed: 20000\n   - Train split: 19770 images\n   - Validation split: 4 images\n   - Test split: 226 images\n\n2. SEGMENTATION METHOD\n   - Algorithm: Otsu Thresholding + Morphological Operations\n   - Target size: (224, 224)\n   - Processing: Gaussian Blur â†’ Otsu â†’ Morphology â†’ Largest Contour â†’ ROI Extraction\n\n3. OUTPUT LOCATION\n   - Segmented images: /kaggle/working/segmented_images\n   - Colorized masks: /kaggle/working/segmented_colormaps\n   - Overlay visualizations: /kaggle/working/segmented_overlays\n   - Mapping file: segmentation_mapping.csv\n\n4. QUALITY METRICS (Average across all classes)\n   - Mean foreground ratio: 0.165\n   - Std foreground ratio: 0.081\n   - Min foreground ratio: 0.009\n   - Max foreground ratio: 0.718\n\n5. METHOD ADVANTAGES\n   âœ“ Fast processing (no training required)\n   âœ“ Reproducible and interpretable\n   âœ“ Well-suited for OCT images with clear tissue/background contrast\n   âœ“ Robust to image variations\n\n6. NEXT STEPS\n   - Proceed to Notebook 3 for data augmentation and preprocessing\n   - Use segmented images as input for your classification models\n   - All outputs ready for downstream ML pipelines\n\n================================================================================\n\n\nZipping outputs for download...\nâœ“ Segmented images zipped: segmented_images.zip\nâœ“ Colorized masks zipped: segmented_colormaps.zip\nâœ“ Overlays zipped: segmented_overlays.zip\n\n================================================================================\nNOTEBOOK 2 COMPLETED SUCCESSFULLY!\n================================================================================\n\nâœ“ Segmented images saved to: /kaggle/working/segmented_images\nâœ“ Total images processed: 20000\n\nGenerated output files:\n  1. segmented_images.zip         (ROI-masked images)\n  2. segmented_colormaps.zip      (Colored mask visualizations)\n  3. segmented_overlays.zip       (Original + mask overlays)\n  4. segmentation_mapping.csv     (Image-to-output mapping)\n  5. segmentation_report.txt      (Summary report)\n  6. segmentation_comparison.png  (Visual comparison)\n\nðŸ“Œ NEXT STEP: Run Notebook 3 for Preprocessing & Augmentation\n================================================================================\n","output_type":"stream"}],"execution_count":1}]}